# Copyright 2021 Eric Lawrey - Australian Institute of Marine Science
#
# MIT License https://mit-license.org/
# This script converts the Geotiff images generated by the Google Earth Engine (GEE) into a
# format for publication to the web. The published version of the dataset uses internal JPEG
# compression with an internal mask. It also has internal tiling (for efficient extraction
# in the middle of the image) and overviews. The raw version sets the no-data value to 0 to ensure
# the image borders come out transparent. 
# Files downloaded from GEE should be saved in input-gee-imagery.
# This script also generates virtual rasters for each region and style combination so that
# all the images in each category can be loaded and manipulated in QGIS as mosaics.
# 
# Script environment - Windows
# To run this Python script you will need GDAL installed and available in the same
# environment as this script.



import os
import subprocess
import glob

# Here we assume that the directory structure is that the SRC_PATH points to
# the images downloaded from GEE organised into folders corresponding to
# regions.
# Two versions of the imagery are produced. A lossless version very similar
# to the original imagery from GEE is saved to the pearl-only directory.
# This imagery is large and is only needed for regenerating the output.
# It is not intended to be published due to the large image file sizes.
# A public version is also generated that saves the imagery using low
# compression JPEG. This format is 4x smaller than the raw output.
# This is saved in OUT_PUBLIC.
# unprocessed-data
#     - CoralSea
#       - *.tif
#     - Global
#       - *.tif
#     - CoralSea
#       - *.tif
#     - Global
#       - *.tif
# OUT_RAW
#     - CoralSea
#       - S2_R1_DeepFalse
#         - *.tif
#       ...
SRC_PATH = '../../unprocessed-data'
OUT_PATH = '../../big-files/data'

OUT_RAW = '../../pearl-only/raw-data/' # Lossless original data (with minor fix ups)
OUT_PUBLIC = '../../big-files/data/out'	# Compressed version of the data suitable for sharing 


if not os.path.exists(OUT_RAW):
	os.mkdir(OUT_RAW)
	print("Making output directory"+OUT_RAW)
	
if not os.path.exists(OUT_PUBLIC):
	os.mkdir(OUT_PUBLIC)
	print("Making output directory"+OUT_PUBLIC)

# List of all the styles to potentially process. Images will be sorted
# into directories matching these style names.
styles = [
	'S2_R1_DeepMarine','S2_R2_DeepMarine','L8_R1_DeepMarine','L8_R2_DeepMarine',
	'S2_R1_DeepFalse', 'S2_R2_DeepFalse','L8_R1_DeepFalse', 'L8_R2_DeepFalse',
	'S2_R1_ReefTop', 'S2_R2_ReefTop','L8_R1_ReefTop', 'L8_R2_ReefTop',
	'S2_R1_Shallow', 'S2_R2_Shallow','L8_R1_Shallow', 'L8_R2_Shallow',
	'S2_R1_TrueColour', 'S2_R2_TrueColour','L8_R1_TrueColour', 'L8_R2_TrueColour',
	'S2_R1_Slope', 'S2_R2_Slope','L8_R1_Slope', 'L8_R2_Slope'
	]
	

# Command line calls for each image type
# -mask 1        Copy the binary mask from channel 1 (red?). This works because the nodata value in the image
#                is 0 and thus all values above 0 get set to 1 in the mask.
# -co TILED=YES  Tile the data into 256x256 blocks instead of pixels rows. Makes extraction of data in the 
#                middle of the image faster.
# -co JPEG_QUALITY=96 Use very low JPEG compression. This compression level was chosen so that there would 
#                be minimal visual loss even when zooming in at 400% zoom. This is important as many key features
#                in the image (coral textures, beach rock) are on a couple of pixels in size. 
# -co COMPRESS=JPEG Set the compression type to JPEG
# -co PHOTOMETRIC=YCBCR Transform the colour space from RGB to YCBCR. This improves the JPEG compression
#                efficiency by ~2x.
# --config GDAL_TIFF_INTERNAL_MASK YES Create an internal mask layer. The important bit here is that this
#                mask is not JPEG compressed so has a crisp boundary.
JPG = 'gdal_translate -mask 1 -co TILED=YES -co JPEG_QUALITY=96 -co COMPRESS=JPEG -co PHOTOMETRIC=YCBCR --config GDAL_TIFF_INTERNAL_MASK YES '

# -co "COMPRESS=LZW" Use lossless compression
# -co "TILED=YES"    Tile the data into blocks (see above)
# -a_nodata 0        Set the nodata value to be 0 so black values become transparent. As part of the GEE
#                    image preparation the brightness intensity of the imagery was scaled to be 1-255 to
#                    ensure there was no overlap between the nodata and the imagery, at the expense that
#                    the imagery doesn't represent true black (0).
LZW = 'gdal_translate -co "COMPRESS=LZW" -co "TILED=YES" -a_nodata 0 '
processing = [
	JPG, JPG, JPG, JPG,	# DeepMarine
	JPG, JPG, JPG, JPG,	# DeepFalse
	LZW, LZW, LZW, LZW,	# ReefTop
	JPG, JPG, JPG, JPG,	# Shallow
	JPG, JPG, JPG, JPG,	# TrueColour
	LZW, LZW, LZW, LZW	# Slope
	]
	

# Iterate through the regions in the SRC_PATH
# Use slash on the end to only pick up directories.
srcRegionDirs = glob.glob(os.path.join(SRC_PATH,"*/"))
regionCount = 1
numRegions = len(srcRegionDirs)
for srcRegionDir in srcRegionDirs:
	# Get the name of the region so that we can include it in the output paths
	# The path being processed is something like: 
	# ../../unprocessed-data\CoralSea\
	# dirname strips off the last slash and basename extracts 'Coral-Sea'
	region = os.path.basename(os.path.dirname(srcRegionDir))
	print('=== Processing region '+region+' ('+str(regionCount)+' of '+str(numRegions)+') ===')
	regionCount = regionCount+1
	
	# Make sure we are dealing with a directory containing images. If not
	# then there is a director in the SRC_PATH not corresponding to the
	# expected structure.
	if not (os.path.isdir(srcRegionDir) and (len(glob.glob(os.path.join(srcRegionDir,"**/*.tif"))) > 0)):
		print('Skipping region '+srcRegionDir)
		continue

	# Search through all the files to be processed, downloaded from Google Earth Engine
	# We don't permanently retain these files because they are large. We should therefore
	# consider the files in the SRC_PATH to be a temporary holding area.
	srcFiles = glob.glob(os.path.join(srcRegionDir,"**/*.tif"))

	fileCount = 1
	numFiles = len(srcFiles)
	for srcFile in srcFiles:
		print("Processing "+str(fileCount)+" of "+str(numFiles)+" files")
		fileCount = fileCount+1
		# Extract the filename from the path so we can create the destination path
		fileName = os.path.basename(srcFile)
		
		# Extract the image style from the file name
		# Examples: 
		# CS_AIMS_Coral-Sea-Features_Img_S2_R1_DeepMarine_55KFA.tif
		# CS_AIMS_Coral-Sea-Features_Img_S2_R2_DeepMarine_55KFA.tif
		# CS_AIMS_Coral-Sea-Features_Img_S2_R1_ReefTop_55KHA.tif
		# In these examples we want 'S2_R1_DeepMarine', 'S2_R2_DeepMarine', 'S2_R1_ReefTop' 
		# Extract this to put each image style in a different directory.
		# Assume that the naming convention is as in the example.
		imgStyle = 'Unknown'
		styleIndex = 1
		for style in styles:
			if(style in fileName):
				imgStyle = style
				break
			styleIndex = styleIndex + 1		# Keep track so we can determine the appropriate 
											# processing
		if imgStyle == 'Unknown':
			raise AssertionError('image contains unknown style: '+srcFile)
		
		# Handle shorting of the names (this was to reduce file path lengths).
		# This is only a temporary hack so we don't have to regenerate and download all the imagery
		# from GEE.
		# Rename the files
		outFileName = fileName.replace("_Imagery_","_Img_")
		
		# ------------- Lossless ----------------
		# Generate the lossless version of the data. This can be used for subsequent reprocessing,
		# but is large 200 - 300 MB per image.
		
		# Create an output directory for the region and style if it doesn't already exists
		outStylePath = os.path.join(OUT_RAW, region, imgStyle)
		print("Out raw path: "+outStylePath)
		if not os.path.exists(outStylePath):
			os.makedirs(outStylePath)
		
		# Temp hack to rename old generated files
		#origDest = os.path.join(outStylePath, fileName)
		#newDest = os.path.join(outStylePath, outFileName)
		
		dest = os.path.join(outStylePath, outFileName)
		print("Dest: "+str(os.path.isfile(dest))+" "+dest)
		# Test if the destination file already exists. If so skip over the conversion.
		if os.path.isfile(dest): 
			print("Skipping "+fileName+" as output already exists "+dest)
		else:
			callStr = LZW+srcFile+' '+dest
			print("system call: "+callStr)
			subprocess.call(callStr)

			#os.rename(origDest,newDest)
		
		# ------------- Compressed output ----------------
		# Generate the lossy version of the data suitable for public delivery.
		# This compresses large images using JPG compression shrinking them to 40 - 50 MB each
		
		# Get the GDAL processing for the style. Some images have LZW and some are JPG compressed.
		gdalProcessing = processing[styleIndex]
		
		# Create an output directory for the region and style if it doesn't already exists
		outStylePath = os.path.join(OUT_PUBLIC, region, imgStyle)
		print("Out public path: "+outStylePath)
		if not os.path.exists(outStylePath):
			os.makedirs(outStylePath)

		dest = os.path.join(outStylePath, outFileName)
		# Test if the destination file already exists. If so skip over the conversion.
		if os.path.isfile(dest): 
			print("Skipping "+fileName+" as output already exists "+dest)
		else:

			subprocess.call(gdalProcessing+srcFile+' '+dest)
			subprocess.call('gdaladdo -r average '+dest)
			

# Build GDAL Virtual Raster for each of the styles. 
# This allows all the images in a particular style to be loaded into QGIS and treated as a single
# layer, making process and styling much more straight forward. We do the building of the 
# virtual layer here because QGIS has two bugs that make its 'Build Virtual Raster' feature
# unusable. The QGIS version (in version 3.18) makes all the file paths absolute making it not possible to
# share the resulting maps, and it converts all the file paths to 8.3 DOS format which makes the
# paths unreadable and probably not compatible across different platforms. 
# If we use gdalbuildvrt directly here the paths are made relative and without the
# conversion to 8.3 DOS names.

outputPaths = [OUT_RAW, OUT_PUBLIC]
for outputPath in outputPaths:
	outRegionDirs = glob.glob(os.path.join(outputPath,"*/"))
	print("=================== Virtual Raster =====================")
	print(outRegionDirs)
	for outRegionDir in outRegionDirs:
		# Look through all the directories that might have been created corresponding to 
		# the image styles. We could have try to process all OUT_PATH folders, looking for
		# any TIF files, however this way we won't accidentially attempt to create a virtual
		# raster for folders created through some other process.
		# Additionally if not all the styles have been downloaded from Google Earth Engine
		# then there will be style directories that don't exist. We must handle this case.
		for style in styles:
			imgDir = os.path.join(outRegionDir,style)
			# Only process if there is a directory for the style and it has some TIF files in it.
			if os.path.isdir(imgDir) and (len(glob.glob(os.path.join(imgDir,"*.tif"))) > 0):
				# Place the virtual raster in the directory with the tif images. This will
				# help keep the relative paths clean.
				print('==== Building Virtual Raster files '+imgDir+' =====')
				cmdString = 'gdalbuildvrt '+style+'.vrt'+' *.tif'
				print(cmdString)
				subprocess.call(cmdString, cwd = imgDir)
			else:
				print("No files found for "+imgDir)